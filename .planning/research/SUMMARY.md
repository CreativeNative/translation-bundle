# Project Research Summary

**Project:** TMI Translation Bundle - AI Documentation Milestone
**Domain:** AI-friendly documentation (llms.txt, CLAUDE.md, Claude Code Skills)
**Researched:** 2026-02-02
**Confidence:** HIGH

## Executive Summary

The TMI Translation Bundle requires AI-friendly documentation following three complementary standards: **llms.txt** for web discovery and AI search indexing, **CLAUDE.md** for local project context, and **Claude Code Skills** for interactive workflows. All three use Markdown as the LLM-optimized format standard. This research synthesized approaches from Anthropic, Mintlify, GitBook, and the emerging llms.txt specification (adopted by 844,000+ sites as of October 2025).

**The recommended approach:** Create a three-layer documentation architecture with progressive disclosure. The existing `llms.md` (343 lines) serves as the comprehensive reference and should be enhanced with a handler chain decision tree and troubleshooting section. Build 2-3 Claude Code Skills for common tasks (entity translation setup, custom handler creation, translation debugging). Move detailed implementation notes to `.claude/references/` subdirectories for on-demand loading. Finally, create a web-facing `llms.txt` for AI discovery linking to GitHub markdown documentation.

**Key risk mitigation:** The bundle's handler chain architecture (priority-based chain-of-responsibility pattern) is not intuitive and creates confusion about execution order. Documentation must make handler priorities explicit through visual decision trees and priority rationale tables. Critical pitfalls include content type misconfiguration (MIME types), information overload (link dumping), broken code examples, and deeply nested reference files that AI can't discover. Address these through validation scripts, CI integration for code examples, and flat reference structures.

## Key Findings

### Recommended Stack

AI documentation in 2026 uses three complementary formats that work together. **llms.txt** provides web discovery through a structured Markdown file at `/llms.txt` with H1, summary blockquote, and organized link sections. AI crawlers and chat interfaces use this to understand and index documentation. **CLAUDE.md** gives Claude Code automatic project context at session start, covering tech stack, commands, code style, and project-specific gotchas (keep under 300 lines, ideally under 100). **Claude Code Skills** provide executable capabilities through YAML frontmatter + Markdown instructions following the open Agent Skills standard (cross-compatible with GitHub Copilot, ChatGPT, Cursor as of Dec 2025).

**Core technologies:**
- **Markdown** (universal format) — Token-efficient, structure-preserving, trained into LLM foundations. All documentation uses .md format
- **llms.txt specification** (web discovery) — Community standard for AI-friendly site documentation, auto-generated by Mintlify/GitBook or created manually
- **Claude Code Skills** (interactive workflows) — Open standard for task-specific AI capabilities with progressive disclosure pattern (SKILL.md + references/ + assets/)

**Critical insight:** Progressive disclosure achieves 70-90% token savings while maintaining quality. Load metadata first (llms.txt index), pull content on-demand (individual markdown pages), drill into references when needed (detailed implementation notes).

### Expected Features

Research identified three feature tiers for effective AI documentation, validated against implementations from Anthropic, Stripe, Zapier, and documentation platforms.

**Must have (table stakes):**
- **H1 project name + summary** — LLMs need immediate context about what they're reading
- **Structured navigation links** — Progressive disclosure enabling metadata-first loading with details on-demand
- **Minimal working example** — Concrete "hello world" pattern showing core usage (import → setup → usage)
- **Code blocks with context** — Always include imports and type hints, never isolated snippets
- **Consistent terminology** — Pick one term per concept, use everywhere (confusing synonyms break AI pattern matching)
- **API reference structure** — Function signatures with arguments, returns, side effects
- **Markdown format** — Serve .md versions to AI, not HTML (token efficiency)
- **Common use cases** — 3-5 real-world scenarios with working code

**Should have (differentiators):**
- **Progressive disclosure architecture** — Three layers: index/metadata → topic details → deep reference (70-90% token savings)
- **SKILL.md for common tasks** — Executable capabilities vs passive documentation
- **Anti-pattern documentation** — Proactive mistake prevention ("Don't do X, do Y instead" with side-by-side examples)
- **Tested code examples** — Integrate documentation snippets into CI/CD for validation
- **Context-aware examples** — Show before/after state, not just isolated snippets
- **Troubleshooting decision trees** — "If X happens, check Y, then Z" flowcharts

**Defer (v2+):**
- **Advanced topics** (custom handlers deep dive) — Complex, lower initial demand
- **Architecture internals** — Useful for contributors, not users
- **Migration guides** — No prior versions to migrate from yet
- **Performance optimization guides** — Premature, wait for usage patterns
- **Video walkthroughs** — High production cost, text works for AI

**Feature dependencies:** Foundation layer (Markdown, H1+summary, terminology, versions) must exist before discovery layer (llms.txt, structured navigation), which enables usage layer (working example, API reference, use cases), which supports excellence layer (progressive disclosure, skills, anti-patterns).

### Architecture Approach

The documentation architecture mirrors the bundle's handler chain pattern. The bundle implements a **priority-based chain of responsibility** where EntityTranslator orchestrates handlers sorted by priority (100→10), each handler checks `supports()`, first match wins, and TranslationArgs context object flows through the chain enabling recursive translation.

**Major components:**

1. **llms.md (comprehensive reference)** — Currently 343 lines, serving as always-loaded context. Should be enhanced with handler decision tree diagram and troubleshooting section. Keep under 500 lines using progressive disclosure to `.claude/references/` for implementation details.

2. **Claude Code Skills (task workflows)** — Create 3 core skills: `entity-translation-setup` (most common task, guides TranslatableInterface implementation), `custom-handler-creator` (extensibility, ensures correct priority selection), `translation-debugger` (troubleshooting, automated diagnosis). Each skill under 200 lines in SKILL.md with details in references/ subdirectories.

3. **Reference files (.claude/references/)** — Three-layer structure: `handlers/` (one file per handler with implementation notes), `architecture/` (chain pattern, context object, recursion, caching), `examples/` (real-world scenarios). Enables on-demand detail loading without bloating main documentation.

4. **llms.txt (web discovery)** — Web-facing index at root linking to GitHub markdown files. Enables AI search discovery and provides structured entry point for AI assistants. Keep to 20-50 high-quality links maximum.

**Key architectural decision:** Flat reference structure (one level deep from SKILL.md) prevents AI from missing content due to partial file reads (head -100 preview behavior). Handler chain gets visual documentation (ASCII decision tree + priority rationale table) because LLMs excel at understanding control flow with explicit visual representations.

### Critical Pitfalls

Research identified 15 domain-specific pitfalls across three severity tiers, validated against official standards and 2025-2026 best practices.

1. **Content type misconfiguration** — llms.txt and markdown files not served as `text/plain` or `text/markdown`, causing AI crawlers to reject files entirely. Silent failure with zero visibility. Prevention: Configure MIME types in .htaccess or server config, verify with `curl -I`. **Critical for Phase 1 (Setup).**

2. **Information overload (link dumping)** — 100+ links in llms.txt or walls of text in SKILL.md. Reduces signal-to-noise ratio, increases latency. Prevention: 20-50 links max in llms.txt, SKILL.md under 500 lines, use progressive disclosure. **Critical for Phase 2 (Content Creation).**

3. **Broken or outdated code examples** — Examples don't work with current library version. Erodes trust, increases support burden. Prevention: Extract examples as unit tests, run in CI/CD, add version pinning comments. **Critical for Phase 3 (Quality Assurance).**

4. **Assuming AI knowledge without verification** — Omitting library-specific context because "AI already knows this." Causes hallucination of plausible-but-incorrect code. Prevention: Document the specific (bundle behavior) not the general (translation concepts), call out non-obvious behaviors, include "gotchas" section. **Critical for Phase 2.**

5. **Third-person voice violation** — Using "I can" or "you can" in SKILL.md description fields. Confuses AI system prompt injection. Prevention: "Translates entities..." not "I can translate..." Enforce with linting. **High priority for Phase 2.**

**Additional moderate pitfalls:** Time-sensitive information (use "old patterns" sections instead of dates), inconsistent terminology (establish style guide early with CI enforcement), deeply nested references (flat structure, one level from SKILL.md), missing UTF-8 encoding, no llms.txt validation, offering too many alternatives without guidance, missing version requirements.

**Bundle-specific concern:** Handler chain has non-obvious interactions (ManyToMany unsupported with SharedAmongstTranslations, priority determines execution order, attribute combinations have edge cases). Must make limitations visible with prominent "Known Limitations" section and decision matrices showing when to use each approach.

## Implications for Roadmap

Based on research, the milestone should be structured in 3 phases over 2-3 weeks, prioritizing immediate value (local development context) then extensibility then web discovery.

### Phase 1: Foundation & Local Context (Week 1, Days 1-2)
**Rationale:** CLAUDE.md provides immediate value for local development with Claude Code. The bundle's handler chain complexity demands clear mental model before implementation.

**Delivers:**
- Enhanced llms.md with handler decision tree (ASCII diagram + priority rationale)
- Troubleshooting section with common issues and diagnostic steps
- "Common Tasks" section linking to skills (prepare infrastructure)
- Consolidated handler descriptions (overview in llms.md, details referenced)

**Addresses features:**
- Structured navigation links (table stakes)
- Visual decision tree for handler chain (differentiator)
- Troubleshooting decision trees (differentiator)

**Avoids pitfalls:**
- Information overload (consolidate details to references/)
- Assuming AI knowledge (explicit handler priority rationale)
- Inconsistent terminology (audit and standardize)

**Research flag:** No additional research needed. Handler chain is well-documented in codebase tests. Standard documentation pattern.

### Phase 2: Core Skills & References (Week 1, Days 3-5)
**Rationale:** Skills provide task-specific guidance for most common operations. References enable progressive disclosure without bloating main documentation.

**Delivers:**
- `.claude/references/handlers/` structure with 2-3 critical handlers documented (PrimaryKey, Scalar, DoctrineObject)
- `entity-translation-setup` skill (SKILL.md + 2 references + 2 templates)
- Handler documentation template for consistency

**Addresses features:**
- SKILL.md for common tasks (differentiator)
- Progressive disclosure architecture (differentiator)
- Context-aware examples (differentiator)
- Minimal working example (table stakes)

**Avoids pitfalls:**
- Deeply nested references (flat structure from SKILL.md)
- Third-person voice violation (enforce in skill descriptions)
- Broken code examples (extract templates from working code)
- Windows path separators (use forward slashes everywhere)

**Research flag:** No additional research needed. Entity setup is core workflow with established patterns in existing bundle.

### Phase 3: Complete Skills & Validation (Week 2)
**Rationale:** Complete skill coverage for debugging and extensibility. Add CI validation to prevent quality erosion over time.

**Delivers:**
- `translation-debugger` skill with diagnostic script
- `custom-handler-creator` skill with handler + test templates
- Remaining 7 handler reference files (complete handlers/)
- Architecture references (chain pattern, recursion, caching)
- Example references (basic entity, embedded, relations)
- CI validation for llms.txt format
- CI validation for code examples (extract and run)

**Addresses features:**
- Tested code examples (differentiator)
- Anti-pattern documentation (differentiator)
- API reference structure (table stakes)
- Common use cases (table stakes)

**Avoids pitfalls:**
- Broken code examples (CI integration)
- No validation (automated checks in pipeline)
- Too many alternatives without guidance (decision matrices)
- Missing version requirements (add badges and notices)

**Research flag:** No additional research needed. Skills follow standard patterns documented in Anthropic best practices.

### Phase 4 (Optional): Web Discovery & Polish (Week 3+)
**Rationale:** Web-facing llms.txt can be deferred without blocking local development. Add based on demand for web visibility.

**Delivers:**
- `/llms.txt` at repository root linking to GitHub markdown
- UTF-8 and MIME type configuration
- Version pinning in all examples
- Quarterly documentation audit process

**Addresses features:**
- llms.txt format (table stakes for web visibility)
- Version information (table stakes)

**Avoids pitfalls:**
- Content type misconfiguration (MIME types)
- Missing UTF-8 encoding (.gitattributes, .editorconfig)
- Time-sensitive information (use version-based sections)

**Research flag:** No additional research needed. llms.txt specification is simple and well-documented.

### Phase Ordering Rationale

- **Local-first approach:** CLAUDE.md and skills provide immediate value for developers using Claude Code, while llms.txt only matters for web hosting. Prioritize what works for contributors first.

- **Progressive disclosure from day one:** Establish `.claude/references/` structure early so documentation scales without bloating core files. Prevents Phase 1 content overload.

- **Skills with templates:** Provide working code templates in skills so AI-generated implementations are correct by construction. Reduces broken example risk.

- **Validation after content:** Write documentation first, then add CI validation. Allows iteration on content before locking down format.

- **Handler chain clarity early:** Decision tree and priority rationale in Phase 1 prevents confusion throughout remaining phases. Understanding execution order is prerequisite for all skills.

### Research Flags

**No phases need additional research.** All core patterns are well-documented:
- llms.txt: Official specification + multiple implementation guides
- Claude Skills: Anthropic official documentation + open standard examples
- Handler chain: Well-understood design pattern + existing bundle architecture
- Symfony bundles: Official documentation standards + best practices

**Standard patterns applicable:**
- Progressive disclosure (documented in Anthropic Skills best practices)
- SKILL.md structure (open Agent Skills standard with examples)
- Handler chain documentation (Chain of Responsibility pattern literature)

**Confidence is HIGH across all phases.** Proceed to roadmap creation with these phase suggestions.

## Confidence Assessment

| Area | Confidence | Notes |
|------|------------|-------|
| Stack | HIGH | Official specifications for llms.txt, CLAUDE.md, Skills. Widespread adoption (844K+ sites for llms.txt, open standard for Skills). |
| Features | HIGH | Validated against implementations from Anthropic, Stripe, Zapier, Mintlify, GitBook. Table stakes features have community consensus. |
| Architecture | HIGH | Handler chain is well-understood design pattern. Bundle architecture documented in existing codebase. Skills structure from official Anthropic guidance. |
| Pitfalls | HIGH | Critical pitfalls verified through official sources (Anthropic, llms.txt spec) and multiple 2025-2026 guides. Moderate pitfalls have industry consensus. |

**Overall confidence:** HIGH

Research is comprehensive and actionable. All table stakes features have HIGH confidence. Differentiators are well-supported with measured benefits (70-90% token savings for progressive disclosure). Anti-patterns are documented from credible sources.

### Gaps to Address

**No critical gaps.** All core requirements are well-researched and documented. Minor areas to validate during implementation:

- **Handler priority sweet spots:** While general priority rationale is clear (100=primary keys, 10=fallback), optimal priority numbers for custom handlers will emerge from real usage. Document as guidelines, iterate based on community feedback.

- **Skill trigger effectiveness:** SKILL.md description fields determine when Claude auto-invokes skills. Test empirically during Phase 2 with real queries to optimize trigger terms. Anthropic provides guidance but real-world effectiveness varies.

- **llms-full.txt generation:** Specification mentions optional single-file variant. Platform support varies (GitBook auto-generates, others don't). Defer decision until Phase 4 when web hosting strategy is clear.

- **Cross-platform skill compatibility:** Skills follow open Agent Skills standard (GitHub Copilot, ChatGPT support announced Dec 2025). Test with multiple AI platforms during Phase 3 to verify portability claims.

**Approach:** Document current best practices based on research. Flag areas needing empirical validation. Iterate based on usage patterns during implementation. High confidence in core architecture, lower confidence in specific optimizations (priorities, triggers) that need real-world testing.

## Sources

### Primary (HIGH confidence)

**Official Specifications:**
- [llmstxt.org](https://llmstxt.org/) — Official llms.txt specification
- [Anthropic: Extend Claude with skills](https://code.claude.com/docs/en/skills) — Official Skills documentation
- [Anthropic: Skill authoring best practices](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices) — Official best practices
- [Anthropic: Claude Code Best Practices](https://code.claude.com/docs/en/best-practices) — CLAUDE.md guidance
- [Agent Skills Standard](https://agentskills.io/) — Open standard specification

**Official Documentation Platforms:**
- [Mintlify: Simplifying docs for AI](https://www.mintlify.com/blog/simplifying-docs-with-llms-txt) — llms.txt implementation guide
- [GitBook: LLM-ready docs](https://gitbook.com/docs/publishing-documentation/llm-ready-docs) — Auto-generation approach

**Anthropic Skills Repository:**
- [anthropics/skills GitHub](https://github.com/anthropics/skills) — Official skills examples

### Secondary (MEDIUM-HIGH confidence)

**2025-2026 Best Practices:**
- [Progressive Disclosure for AI](https://alexop.dev/posts/stop-bloating-your-claude-md-progressive-disclosure-ai-coding-tools/) — Context management with measured benefits (70-90% token savings)
- [Writing a good CLAUDE.md](https://www.humanlayer.dev/blog/writing-a-good-claude-md) — Best practices guide
- [Claude Agent Skills Deep Dive](https://leehanchung.github.io/blogs/2025/10/26/claude-skills-deep-dive/) — Technical analysis
- [Inside Claude Code Skills](https://mikhail.io/2025/10/claude-code-skills/) — Structure and invocation

**API Documentation Standards:**
- [API Documentation Best Practices 2025](https://www.theneo.io/blog/api-documentation-best-practices-guide-2025) — Industry standards
- [Code Documentation Best Practices 2026](https://www.qodo.ai/blog/code-documentation-best-practices-2026/) — Testing and validation

**LLM Optimization:**
- [Optimizing technical documentation for LLMs](https://dev.to/johtom/optimizing-technical-documentations-for-llms-4bcd) — Documentation optimization patterns
- [LLM Documentation Optimization](https://redocly.com/blog/optimizations-to-make-to-your-docs-for-llms) — Platform guidance
- [Why Markdown is the best format for LLMs](https://medium.com/@wetrocloud/why-markdown-is-the-best-format-for-llms-aa0514a409a7) — Token efficiency analysis

**Handler Chain Patterns:**
- [Multi-Step LLM Chains: Best Practices](https://www.deepchecks.com/orchestrating-multi-step-llm-chains-best-practices/) — Chain patterns for AI
- [AWS Agentic AI Patterns](https://docs.aws.amazon.com/pdfs/prescriptive-guidance/latest/agentic-ai-patterns/agentic-ai-patterns.pdf) — Router chains and decision trees

**Common Pitfalls:**
- [5 Common llms.txt Mistakes](https://medium.com/@singularity-digital-marketing/5-common-mistakes-when-creating-your-llms-txt-and-how-to-fix-them-c0f9cb038dce) — Validation and configuration
- [LLM Anti-Patterns](https://medium.com/marvelous-mlops/patterns-and-anti-patterns-for-building-with-llms-42ea9c2ddc90) — Context stuffing and other issues
- [RAG Anti-Patterns](https://medium.com/@2nick2patel2/llm-rag-anti-patterns-stop-stuffing-context-c79c11a2529d) — Information overload

**Symfony Standards:**
- [Best Practices for Reusable Bundles](https://symfony.com/doc/current/bundles/best_practices.html) — Symfony official standards

### Tertiary (Supporting Context)

- [llms-txt.io Examples](https://llms-txt.io/blog/companies-using-llms-txt-examples) — Real-world implementations
- [VoltAgent/awesome-agent-skills](https://github.com/VoltAgent/awesome-agent-skills) — 200+ open source skills
- [Best llms.txt Implementation Platforms](https://buildwithfern.com/post/best-llms-txt-implementation-platforms-ai-discoverable-apis) — Platform comparison

---
*Research completed: 2026-02-02*
*Ready for roadmap: yes*
